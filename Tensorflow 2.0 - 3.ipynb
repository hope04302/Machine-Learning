{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNpW2ZlrE97YwcAXyIa995q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6M7SZJu9DD8j"},"source":["# 시작하세요! 텐서플로 2.0 프로그래밍 - 김환희 지음\n","- https://github.com/wikibook/tf2"]},{"cell_type":"markdown","metadata":{"id":"O91kAJfWatt-"},"source":["# 사용할 모듈"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUS3vGxcxnbt"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import math\n","import random as rd"]},{"cell_type":"markdown","source":["# 시작하기에 앞서\n","- 여기서부터는 심화된 내용(안 배워도 됨)\n","- 다만, 이미 있는 것을 불러오거나 (8장),\n","굳이 라벨 같은 것을 안 붙여도 알아서 분류하거나(비지도학습; 9장),\n","알파고처럼 게임 같은 것을 학습시키고 싶다면(10장)\n","배워보는 것도 좋음\n","- [강화 학습의 예시](https://www.youtube.com/watch?v=v3UBlEJDXR0&t=200s) (10장에서 간단한 예제를 배움)"],"metadata":{"id":"SIIUt0c4sATp"}},{"cell_type":"markdown","source":["# 8장 사전 훈련된 모델 다루기"],"metadata":{"id":"dBFMPSKY06lb"}},{"cell_type":"markdown","source":["## 텐서플로 허브(Tensorflow Hub)\n","- 각종 신경망을 공유"],"metadata":{"id":"jUkyE3AN1Aly"}},{"cell_type":"code","source":[],"metadata":{"id":"mvZ7-DpK1WAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 전이 학습(Tranfer Learning)\n","- 이미 학습된 모델을 다른 작업에 사용하기 위하여 추가로 학습시킴\n","  - 특징을 추출(특징 추출기; Feature Extractor)\n","  - 모델의 일부를 재학습"],"metadata":{"id":"2CSNLGjBqzh8"}},{"cell_type":"markdown","source":["## 신경 스타일 전이(Neural Style Tranfer)"],"metadata":{"id":"i4Achbr60_zF"}},{"cell_type":"code","source":[],"metadata":{"id":"jjjyFgUKrQtS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 9장 오토인코더(AutoEncoder)\n","자기 자신을 활용하여 자기 자신과 같은 형태의 무언가를 생성\n","  - 모자이크가 된 그림을 입력하면, 모자이크를 없앤 그림을 출력\n","  - 압축 파일 정보를 입력하면, 원 상태의 정보를 출력"],"metadata":{"id":"CnpbhKOYrCuS"}},{"cell_type":"code","source":[],"metadata":{"id":"Kfn2_2b3zYCz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 클러스터링(Clustering)\n","- 지도학습(Supervised Learning)\n","  - 이미 라벨링이 된(즉 정답을 아는) 문제를 학습\n","- 비지도 학습(Unsupervised Learning)\n","  - 라벨링이 되지 않은(정답을 모르는) 문제를 학습해, 그 분포를 바탕으로 해석\n","  - 크게 군집화, 분포 추정이 있음 (나무위키 피셜)\n","  - 클러스터링 알고리즘으로 군집화를 함"],"metadata":{"id":"spqZcHnvxjmi"}},{"cell_type":"code","source":[],"metadata":{"id":"4QOGb2kW1598"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 초고해상도 이미지 얻기"],"metadata":{"id":"6Wt5h38c1qed"}},{"cell_type":"code","source":[],"metadata":{"id":"D1N5e94h15eG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 이미지 분할(Segmentation)"],"metadata":{"id":"qYbpJhTC1uGG"}},{"cell_type":"code","source":[],"metadata":{"id":"xd5UzY6brPNg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 10장 강화학습(Reinforcement Learning)\n","- 기존의 신경망: 정답과 예측 간의 오차를 통해 가중치와 편향을 학습\n","- 강화학습: 행동(action)에서의 보상(reward)을 통해 특정 행동을 더 하도록 학습"],"metadata":{"id":"gbFhIDFWrGQA"}},{"cell_type":"markdown","source":["## Gym이란?\n","- OpenAI에서 발표한 환경으로, 강화학습을 위해 마련\n","  - 환경(Environment)\n","  - 에이전트(Agent): 문제를 푸는 엔티티?\n","  - 행동(Action) -> 보상(Reward): 한 시간 단위(Time Step)마다\n","  - 목표에 도달하면: 하나의 에피소드(Episode)"],"metadata":{"id":"LZcnnJsl6Yz5"}},{"cell_type":"code","source":[],"metadata":{"id":"ei4nNDYwrFim"},"execution_count":null,"outputs":[]}]}